{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI Poker dataset classification with Scikit-learn\n",
    "**Student Name: Nguyen Minh Khoi**\\\n",
    "**Student ID: 21127081**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libraries for this kernel are:\n",
    "\n",
    "• Pandas\n",
    "\n",
    "• Seaborn\n",
    "\n",
    "• Matplotlib\n",
    "\n",
    "• Graphviz\n",
    "\n",
    "• Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and merge manually"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data to Pandas dataframes and save into poker-hand-data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./input/poker-hand-training-true.data', header=None)\n",
    "test_data = pd.read_csv('./input/poker-hand-testing.data', header=None)\n",
    "\n",
    "merged_data = pd.concat([train_data, test_data])\n",
    "merged_file = merged_data.to_csv('poker-hand-data.csv', index=False, header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data sets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We need to prepare four subsets from merged data:\n",
    "\n",
    "• features_train\n",
    "\n",
    "• features_test\n",
    "\n",
    "• labels_train\n",
    "\n",
    "• labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = merged_data.iloc[:, :-1]\n",
    "labels = merged_data.iloc[:, -1]\n",
    "\n",
    "split_ratios = [0.4, 0.6, 0.8, 0.9]\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for split_ratio in split_ratios:\n",
    "    datasets[split_ratio] = train_test_split(features, labels, test_size=1-split_ratio, stratify=labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare class names of Poker Hand\n",
    "class_names = ['Nothing', 'One pair', 'Two pairs', 'Three of a kind', 'Straight', 'Flush', 'Full house', 'Four of a kind', 'Straight flush', 'Royal flush']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the distributions of classes in all the data sets with Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_barplot(type_set):\n",
    "    for split_ratio in split_ratios:\n",
    "        features_train, features_test, labels_train, labels_test = datasets[split_ratio]\n",
    "        if type_set == \"original\":\n",
    "            labels = pd.read_csv('poker-hand-data.csv', header=None)\n",
    "            class_counts = labels.iloc[:, -1].value_counts().sort_index()\n",
    "        elif type_set == \"train\":\n",
    "            class_counts = labels_train.value_counts().sort_index()\n",
    "        else:\n",
    "            class_counts = labels_test.value_counts().sort_index()\n",
    "            \n",
    "        class_counts = class_counts.reindex(range(10), fill_value=0)\n",
    "        for i in range(len(class_counts)):\n",
    "            class_counts = class_counts.rename({i: class_names[i]})\n",
    "\n",
    "        df = pd.DataFrame(class_counts, class_names)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plots = sns.barplot(x=class_names, y=class_counts, data=df)\n",
    "\n",
    "        for bar in plots.patches:\n",
    "            plots.annotate(format(float(bar.get_height()), '.1f'), (bar.get_x() + bar.get_width() / 2,\n",
    "                            bar.get_height()), ha='center', va='center', size=8, xytext=(0, 6), textcoords='offset points')\n",
    "        \n",
    "        if type_set == \"original\":\n",
    "            plt.title(f'Distribution of the original set')\n",
    "        elif type_set == \"train\": \n",
    "            plt.title(f'Distribution of training sets for split ratio {round(split_ratio*100)}%')\n",
    "        else:\n",
    "            plt.title(f'Distribution of test sets for split ratio {round((1- split_ratio)*100)}%')\n",
    "\n",
    "        plt.xticks(range(len(class_counts)), class_names, rotation=90)\n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "\n",
    "        if type_set == \"original\":\n",
    "            return\n",
    "\n",
    "visualize_barplot(\"original\")\n",
    "visualize_barplot(\"train\")\n",
    "visualize_barplot(\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the decision tree classifiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier is a class capable of performing multi-class classification on a dataset.\n",
    "\n",
    "Classification criteria: Entropy\n",
    "\n",
    "We use graphviz to render decision tree into pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ratio in split_ratios:\n",
    "    features_train, features_test, labels_train, labels_test = datasets[ratio]\n",
    "    dtc = DecisionTreeClassifier(criterion='entropy')\n",
    "    dtc.fit(features_train, labels_train)\n",
    "\n",
    "    depth = 5\n",
    "    dot_data = export_graphviz(dtc, max_depth=depth, feature_names=class_names, rounded=True, out_file=None, filled=True, special_characters=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render(directory=\"decision-tree-graph\", filename=f\"graph_{int(ratio*100)}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the decision tree classifiers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report: A classification report is a summary of the performance of a classification model.\n",
    "\n",
    "Confusion Matrix: A confusion matrix is a table that is used to evaluate the performance of a classification model.\n",
    "\n",
    "To visualize the Confustion Matrix, we use heatmap. Heatmaps use color-coding to represent the values in the matrix, making it easier to interpret the results of the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ratio in split_ratios:\n",
    "    features_train, features_test, labels_train, labels_test = datasets[ratio]\n",
    "    dtc = DecisionTreeClassifier(criterion='entropy')\n",
    "    dtc.fit(features_train, labels_train)\n",
    "    labels_pred_dtc = dtc.predict(features_test)\n",
    "    print(f\"Classification report for {ratio}\")\n",
    "    print(classification_report(labels_test, labels_pred_dtc, zero_division=0))\n",
    "    confusion_matrix(labels_test, labels_pred_dtc)\n",
    "    table = pd.DataFrame(confusion_matrix(labels_test, labels_pred_dtc))\n",
    "    plt.title(f\"UCI Poker Heat Map for {round(ratio*100)}%\",fontsize=16)\n",
    "    sns.heatmap(table, annot=True, fmt='.1f', cmap='viridis', annot_kws={'size': 6.5})\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The depth and accuracy of a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.8\n",
    "features_train, features_test, labels_train, labels_test = datasets[test_ratio]\n",
    "list_depths = [None, 2, 3, 4, 5, 6, 7]\n",
    "for depth in list_depths:\n",
    "    dtc = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)\n",
    "    dtc.fit(features_train, labels_train)\n",
    "    if depth == None:\n",
    "        visual_depth = 5\n",
    "    else:\n",
    "        visual_depth = None\n",
    "    dot_data = export_graphviz(dtc, max_depth=visual_depth, feature_names=class_names, rounded=True, out_file=None, filled=True, special_characters=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render(directory=\"decision-tree-graph\", filename=f\"graph_{int(ratio*100)}_{depth}\")\n",
    "    labels_pred_dtc = dtc.predict(features_test)\n",
    "    print(f\"Accuracy score for {test_ratio} in depth {depth}: \")\n",
    "    print(accuracy_score(labels_test, labels_pred_dtc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
